import medmnist
from medmnist import PathMNIST, INFO
import numpy as np
import matplotlib.pyplot as plt
import torch
from torch.utils.data import DataLoader
from torchvision import transforms, models
from torchvision.transforms import InterpolationMode
import torch.nn as nn
import torch.optim as optim
import time
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import copy

device= torch.device("cuda"if torch.cuda.is_available() else "cpu")
print(device)

info = INFO['pathmnist']
n_classes = len(info['label'])
name_classes =  info['label']
channels = info['n_channels']

ImageNet_mean = [0.485, 0.456, 0.406]
ImageNet_std = [0.229, 0.224, 0.225]

transform = transforms.Compose([
    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.ToTensor(),
    transforms.Normalize(mean = ImageNet_mean, std=ImageNet_std)
])

train_dataset=PathMNIST(split='train', transform=transform)
val_dataset = PathMNIST(split='val', transform=transform)
test_dataset = PathMNIST(split='test', transform=transform)

image, label = train_dataset[0]
label = torch.tensor(label).long()

batch_size = 32

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle = False)

model = models.efficientnet_b0(weights='DEFAULT')
for param in model.parameters():
    param.requires_grad = True    
in_features = model.classifier[1].in_features

model.classifier = nn.Sequential(
    nn.Linear(in_features, 256),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(256, n_classes)
)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW([
    {'params': model.features.parameters(), 'lr': 2e-5},
    {'params': model.classifier.parameters(), 'lr': 1e-4}
], weight_decay=1e-2)

scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,
    patience=5,
    min_lr=1e-6,
    verbose=True
)

epochs = 20
best_val_loss = float('inf')
epochs_no_improve = 0
best_model_weights = None

train_losses, val_losses = [], []
train_accs, val_accs = [], []

start_time = time.time()

for epoch in range(epochs):
    model.train()
    r_loss, correct, total = 0, 0, 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.squeeze().long().to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        r_loss += loss.item() * images.size(0)
        _, pred = torch.max(outputs, 1)
        correct += (pred == labels).sum().item()
        total += labels.size(0)
        
    train_losses.append(r_loss / total)
    train_accs.append(correct / total)

    model.eval()
    v_loss, v_correct, v_total = 0, 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.squeeze().long().to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            v_loss += loss.item() * images.size(0)
            _, pred = torch.max(outputs, 1)
            v_correct += (pred == labels).sum().item()
            v_total += labels.size(0)
            
    current_val_loss = v_loss / v_total 
    val_losses.append(current_val_loss)
    val_accs.append(v_correct / v_total)

    scheduler.step(current_val_loss)
    lr_backbone = optimizer.param_groups[0]['lr']
    lr_head = optimizer.param_groups[1]['lr']

    if current_val_loss < best_val_loss:
        best_val_loss = current_val_loss
        epochs_no_improve = 0
        best_model_weights = copy.deepcopy(model.state_dict())
    else:
        epochs_no_improve += 1

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(train_accs, label='Train Acc')
plt.plot(val_accs, label='Val Acc')
plt.legend()
plt.show()

model.eval()
all_labels = []
all_preds = []
all_probs = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.squeeze().to(device)
        outputs = model(images)
        probs = torch.softmax(outputs, dim=1)
        _, predicted = torch.max(outputs, 1)

        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(predicted.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())

all_labels = np.array(all_labels)
all_preds = np.array(all_preds)
all_probs = np.array(all_probs)

cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', xticklabels=name_classes.values(), yticklabels=name_classes.values())
cr=classification_report(all_labels, all_preds, target_names=name_classes.values())
